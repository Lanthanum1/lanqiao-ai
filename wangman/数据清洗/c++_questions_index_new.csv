index,content
常用的 Linux 命令,常用的 Linux 命令有：cd：切换当前目录 ls：查看当前文件与目录 grep：通常与管道命令一起使用，用于对一些命令的输出进行筛选加工 cp：复制文件或文件夹 mv：移动文件或文件夹 rm：删除文件或文件夹 ps：查看进程情况 kill：向进程发送信号 tar：对文件进行打包 cat：查看文件内容 top：查看操作系统的信息，如进程、CPU占用率、内存信息等（实时） free：查看内存使用情况 pwd：显示当前工作目录
静态库和动态库如何制作及使用，区别是什么,静态库的制作和使用 - 命名规则 Linux : libxxx.a lib : 前缀（固定） xxx : 库的名字，自己起 .a : 后缀（固定） Windows : libxxx.lib - 制作 a.gcc 获得 .o 文件 gcc xxx.c xxx.c -c b.将 .o 文件打包，使用 ar 工具（archive） ar rcs libxxx.a xxx.o xxx.o - 使用 静态库使用需要有库文件和头文件，编译程序时通过 “-l 静态库名” 参数进行编译。 动态库的制作 - 命名规则 Linux : libxxx.so lib : 前缀（固定） xxx : 库的名字，自己起 .so : 后缀（固定） Windows : libxxx.dll - 制作 a.gcc 得到 .o 文件，得到和位置无关的代码 gcc -c –fpic/-fPIC a.c b.c b.gcc 得到动态库 gcc -shared a.o b.o -o libcalc.so - 使用 动态库使用需要有库文件和头文件，编译程序时通过 “-l 动态库名” 参数进行编译。在运行程序之前还需要配置动态库的加载路径，程序才能够正常运行。 静态库和动态的区别 - 静态库 gcc 进行链接时，会把静态库中代码打包到可执行程序中，编译时加载；发布程序时无需提供静态库，移植方便；消耗内存，更新部署发布麻烦。 - 动态库 gcc 进行链接时，动态库的代码不会被打包到可执行程序中，运行时加载；发布程序时需要提供动态库；内存占用小，更新部署发布简单。
动态库静态库的区别和优缺点,静态库和动态库的区别： 命令方式不同 - 静态库命名 Linux : libxxx.a lib : 前缀（固定） xxx : 库的名字，自己起 .a : 后缀（固定） Windows : libxxx.lib - 动态库命名 Linux : libxxx.so lib : 前缀（固定） xxx : 库的名字，自己起 .so : 后缀（固定） Windows : libxxx.dll 链接时间和方式不同 - 静态库的链接是将整个函数库的所有数据在编译时都整合进了目标代码 - 动态库的链接是程序执行到哪个函数链接哪个函数的库 静态库和动态库的优缺点： 静态库优缺点 - 优点：发布程序时无需提供静态库，移植方便，运行速度相对快些 - 缺点：静态链接生成的可执行文件体积较大，消耗内存，如果所使用的静态库发生更新改变，程序必须重新编译，更新麻烦。 动态库优缺点 - 优点：更加节省内存并减少页面交换，动态库改变并不影响使用的程序，动态函数库升级比较方便 - 缺点：发布程序时需要提供动态库
进程调度算法有哪些,调度算法是指根据系统的资源分配策略所规定的资源分配算法。常见的进程调度算法有： 先来先服务（FCFS）调度算法 先来先去服务调度算法是一种最简单的调度算法，也称为先进先出或严格排队方案。每次调度都是从后备作业（进程）队列中选择一个或多个最先进入该队列的作业（进程），将它们调入内存，为它们分配资源、创建进程，当每个进程就绪后，它加入就绪队列。当前正运行的进程停止执行，选择在就绪队列中存在时间最长的进程运行。 短作业优先（SJF）调度算法 短作业优先（SJF）的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业（进程），将它们调入内存运行，短进程优先（SPF）调度算法从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即执行，直到完成或者发生某件事而阻塞时，才释放处理机。 优先级调度算法 优先级调度算法又称优先权调度算法，该算法既可以用于作业调度，也可以用于进程调度，该算法中的优先级用于描述作业运行的紧迫程度。在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最髙的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列；在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。 高响应比优先调度算法 高响应比优先调度算法主要用于作业调度，该算法是对 FCFS 调度算法和 SJF 调度算法的一种综合平衡，同时考虑每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。  时间片轮转调度算法 时间片轮转调度算法主要适用于分时系统。每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。 多级反馈队列调度算法 多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合和发展，通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。 
进程通信的方式有哪些,进程间通信主要包括：管道、命名管道、信号、消息队列、共享内存、内存映射、信号量、Socket： 管道 管道也叫无名（匿名）管道，它是是 UNIX 系统 IPC（进程间通信）的最古老形式，所有的 UNIX 系统都支持这种通信机制。管道本质其实是内核中维护的一块内存缓冲区，Linux 系统中通过 pipe() 函数创建管道，会生成两个文件描述符，分别对应管道的读端和写端。无名管道只能用于具有亲缘关系的进程间的通信。 命名管道 匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道（FIFO），也叫命名管道、FIFO文件。有名管道（FIFO）不同于匿名管道之处在于它提供了一个路径名与之关联，以 FIFO 的文件形式存在于文件系统中，并且其打开方式与打开一个普通文件是一样的，这样即使与 FIFO 的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过 FIFO 相互通信，因此，通过 FIFO 不相关的进程也能交换数据。 信号 信号是 Linux 进程间通信的最古老的方式之一，是事件发生时对进程的通知机制，有时也称之为软件中断，它是在软件层次上对中断机制的一种模拟，是一种异步通信的方式。信号可以导致一个正在运行的进程被另一个正在运行的异步进程中断，转而处理某一个突发事件。 消息队列 消息队列就是一个消息的链表，可以把消息看作一个记录，具有特定的格式以及特定的优先级，对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程则可以从消息队列中读走消息，消息队列是随内核持续的。 共享内存 共享内存允许两个或者多个进程共享物理内存的同一块区域（通常被称为段）。由于一个共享内存段会称为一个进程用户空间的一部分，因此这种 IPC 机制无需内核介入。所有需要做的就是让一个进程将数据复制进共享内存中，并且这部分数据会对其他所有共享同一个段的进程可用。与管道等要求发送进程将数据从用户空间的缓冲区复制进内核内存和接收进程将数据从内核内存复制进用户空间的缓冲区的做法相比，这种 IPC 技术的速度更快。 内存映射 内存映射（Memory-mapped I/O）是将磁盘文件的数据映射到内存，用户通过修改内存就能修改磁盘文件。 信号量 信号量主要用来解决进程和线程间并发执行时的同步问题，进程同步是并发进程为了完成共同任务采用某个条件来协调它们的活动。对信号量的操作分为 P 操作和 V 操作，P 操作是将信号量的值减 1，V 操作是将信号量的值加 1。当信号量的值小于等于 0 之后，再进行 P 操作时，当前进程或线程会被阻塞，直到另一个进程或线程执行了 V 操作将信号量的值增加到大于 0 之时。 Socket 套接字（Socket），就是对网络中不同主机上的应用进程之间进行双向通信的端点的抽象。一个套接字就是网络上进程通信的一端，提供了应用层进程利用网络协议交换数据的机制。Socket 一般用于网络中不同主机上的进程之间的通信。
线程的通信方式,线程间无需特别的手段进行通信，因为线程间可以共享一份全局内存区域，其中包括初始化数据段、未初始化数据段，以及堆内存段等，所以线程之间可以方便、快速地共享信息。只需要将数据复制到共享（全局或堆）变量中即可。不过，要考虑线程的同步和互斥，应用到的技术有： 信号 Linux 中使用 pthread_kill() 函数对线程发信号。 互斥锁、读写锁、自旋锁 互斥锁确保同一时间只能有一个线程访问共享资源，当锁被占用时试图对其加锁的线程都进入阻塞状态（释放 CPU 资源使其由运行状态进入等待状态），当锁释放时哪个等待线程能获得该锁取决于内核的调度。 读写锁当以写模式加锁而处于写状态时任何试图加锁的线程（不论是读或写）都阻塞，当以读状态模式加锁而处于读状态时“读”线程不阻塞，“写”线程阻塞。读模式共享，写模式互斥。 自旋锁上锁受阻时线程不阻塞而是在循环中轮询查看能否获得该锁，没有线程的切换因而没有切换开销，不过对 CPU 的霸占会导致 CPU 资源的浪费。 所以自旋锁适用于并行结构（多个处理器）或者适用于锁被持有时间短而不希望在线程切换产生开销的情况。 条件变量 条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的，条件变量始终与互斥锁一起使用。 信号量 信号量实际上是一个非负的整数计数器，用来实现对公共资源的控制。在公共资源增加的时候，信号量就增加；公共资源减少的时候，信号量就减少；只有当信号量的值大于0的时候，才能访问信号量所代表的公共资源。
进程和线程的区别,进程和线程的主要差别在于它们是不同的操作系统资源管理方式。 进程有独立的地址空间，线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间； 进程和线程切换时，需要切换进程和线程的上下文，进程的上下文切换时间开销远远大于线程上下文切换时间，耗费资源较大，效率要差一些； 进程的并发性较低，线程的并发性较高； 每个独立的进程有一个程序运行的入口、顺序执行序列和程序的出口，但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制； 系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了 CPU 外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源； 一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。
介绍一下死锁，产生的必要条件，产生的原因，怎么预防死锁,死锁 两个或两个以上的进程在执行过程中，因争夺共享资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。这些永远在互相等待的进程称为死锁进程。 产生死锁的必要条件 虽然进程在运行过程中，可能发生死锁，但死锁的发生也必须具备一定的条件，死锁的发生必须具备以下四个必要条件： - 互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放； - 请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放； - 不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放； - 环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合 {P0，P1，P2，···，Pn} 中的 P0 正在等待一个 P1 占用的资源；P1 正在等待 P2 占用的资源，……，Pn 正在等待已被 P0 占用的资源。 产生死锁的原因 - 竞争资源 - 进程间推进顺序非法 预防死锁 - 有序资源分配法 - 银行家算法
select的原理以及缺点,select 是一种IO多路复用技术，它的主旨思想是： 首先要构造一个关于文件描述符的列表，将要监听的文件描述符添加到该列表中，这个文件描述符的列表数据类型为 fd_set，它是一个整型数组，总共是 1024 个比特位，每一个比特位代表一个文件描述符的状态。比如当需要 select 检测时，这一位为 0 就表示不检测对应的文件描述符的事件，为 1 表示检测对应的文件描述符的事件。 调用 select() 系统调用，监听该列表中的文件描述符的事件，这个函数是阻塞的，直到这些描述符中的一个或者多个进行 I/O 操作时，该函数才返回，并修改文件描述符的列表中对应的值，0 表示没有检测到该事件，1 表示检测到该事件。函数对文件描述符的检测的操作是由内核完成的。 select() 返回时，会告诉进程有多少描述符要进行 I/O 操作，接下来遍历文件描述符的列表进行 I/O 操作。 select 的缺点： 每次调用select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大； 同时每次调用 select 都需要在内核遍历传递进来的所有 fd，这个开销在 fd 很多时也很大；select 支持的文件描述符数量太小了，默认是 1024（由 fd_set 决定）； 文件描述符集合不能重用，因为内核每次检测到事件都会修改，所以每次都需要重置； 每次 select 返回后，只能知道有几个 fd 发生了事件，但是具体哪几个还需要遍历文件描述符集合进一步判断。
epoll的原理,epoll 是一种更加高效的 IO 复用技术，epoll 的使用步骤及原理如下：  调用 epoll_create() 会在内核中创建一个 eventpoll 结构体数据，称之为 epoll 对象，在这个结构体中有 2 个比较重要的数据成员，一个是需要检测的文件描述符的信息 struct_root rbr（红黑树），还有一个是就绪列表struct list_head rdlist，存放检测到数据发送改变的文件描述符信息（双向链表）； 调用 epoll_ctrl() 可以向 epoll 对象中添加、删除、修改要监听的文件描述符及事件；  调用 epoll_wt() 可以让内核去检测就绪的事件，并将就绪的事件放到就绪列表中并返回，通过返回的事件数组做进一步的事件处理。 epoll 的两种工作模式： LT 模式（水平触发） LT（Level - Triggered）是缺省的工作方式，并且同时支持 Block 和 Nonblock Socket。在这种做法中，内核检测到一个文件描述符就绪了，然后可以对这个就绪的 fd 进行 IO 操作，如果不作任何操作，内核还是会继续通知。  ET 模式（边沿触发） ET（Edge - Triggered）是高速工作方式，只支持 Nonblock socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过 epoll 检测到。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了。但是请注意，如果一直不对这个 fd 进行 IO 操作（从而导致它再次变成未就绪），内核不会发送更多的通知（only once）。 ET 模式在很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。epoll 工作在 ET 模式的时候，必须使用非阻塞套接口，以避免由于一个文件描述符的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 
介绍一下互斥锁和自旋锁,互斥锁 互斥锁也称为互斥量（Mutex），是一种用来保护临界区的特殊变量， 它可以处于锁定（locked） 状态， 也可以处于解锁（unlocked） 状态： - 如果互斥锁是锁定的， 就是某个特定的线程正持有这个互斥锁 - 如果没有线程持有这个互斥锁，那么这个互斥锁就处于解锁状态 每个互斥锁内部有一个线程等待队列，用来保存等待该互斥锁的线程。当互斥锁处于解锁状态时， 如果某个线程试图获取这个互斥锁， 那么这个线程就可以得到这个互斥锁而不会阻塞；当互斥锁处于锁定状态时， 如果某个线程试图获取这个互斥锁， 那么这个线程将阻塞在互斥锁的等待队列内。 自旋锁 自旋锁与互斥锁类似，但它不是通过休眠使进程阻塞，而是在获取锁之前一直处于忙等（自旋）阻塞状态。自旋锁可以用于以下情况：锁被持有的时间短，而且线程并不希望在重新调度上花费太多的成本。 自旋锁最多只能被一个可执行线程持有，如果一个执行线程试图获得一个已经被持有的自旋锁，那么该线程就会一直进行忙循环 - 旋转 - 等待锁重新可用。
说说 TCP 和 UDP 的区别,首先，UDP 协议和 TCP 协议都属于运输层协议，都是为应用层程序服务，同时具有复用和分用的功能。复用指不同的应用层协议可以共用 UDP 协议和 TCP 协议，而分用则是将数据报解析后分发给不同的应用层程序。UDP 提供面向无连接基于数据报的不可靠传输，而 TCP 提供面向连接基于字节流的可靠传输。在实时性要求高的场景中，UDP 表现良好，因为它快速且不受网络不稳定性的影响，适用于需要源主机以恒定速率发送数据报的应用，如语音通话和视频会议等。相反，在对数据准确性有要求但速度要求不强的场景中，TCP 表现更佳。TCP 是面向连接的，具有可靠交付和拥塞控制等机制，适合于 FTP、HTTP/HTTPS 等需要稳定传输的应用。UDP协议：- 面向无连接，不需要三次握手和四次挥手- 尽最大努力交付，不保证数据传输的可靠性- 面向报文，每次收发都是一整个报文段- 没有拥塞控制，不保证数据传输的稳定性- 支持一对一、一对多、多对一和多对多的通信方式- 首部开销很小（8字节）TCP协议：- 面向连接，需要三次握手和四次挥手- 单播，只能端对端的连接- 可靠交付，具有确认、重传、拥塞控制等机制- 全双工通讯，允许双方同时发送信息- 面向字节流，以字节流的方式进行传输- 头部开销大（最少20字节）UDP 的优点是快速，节省网络资源，适合实时性要求高的场景；缺点是不可靠不稳定，容易造成数据丢失。TCP 的优点是可靠稳定，适合对数据准确性有要求的场景；缺点是速度较慢，消耗系统资源多。
说说 TCP 三次握手四次挥手过程,TCP连接的三次握手过程：1. 第一次握手：   - 客户端向服务器端发送连接请求报文段，包含自身数据通讯初始序号，进入SYN-SENT状态。2. 第二次握手：   - 服务器端收到连接请求报文段后，如果同意，发送应答，包含自身数据通讯初始序号，进入SYN-RECEIVED状态。3. 第三次握手：   - 客户端收到应答后，向服务器端发送确认报文，确认连接成功建立，进入ESTABLISHED状态。TCP连接的四次挥手过程：1. 第一次挥手：   - 客户端认为数据发送完毕，向服务器端发送连接释放请求。2. 第二次挥手：   - 服务器端收到连接释放请求，告知应用层释放TCP连接，并发送ACK包，进入CLOSE-WT状态。3. 第三次挥手：   - 服务器端数据发送完毕后，向客户端发送连接释放请求，进入LAST-ACK状态。4. 第四次挥手：   - 客户端收到连接释放请求，向服务器端发送确认应答报文，进入TIME-WT状态，持续2倍的MSL（最长报文段寿命）。若期间没有收到服务器端的数据报文，进入CLOSED状态。服务器端收到确认应答后，也进入CLOSED状态。客户端向服务器端发起TCP连接的详细过程：1. 初始状态：   - 客户端和服务器端都处于CLOSED（关闭）状态。2. 连接请求发起：   - 客户端向服务器端发出连接请求报文段，其中的同步位SYN置为1，选择初始序号seq=x。客户端进入SYN-SENT状态。3. 连接确认：   - 服务器端收到连接请求报文后，如果同意连接，发送确认响应，其中的SYN和ACK都置为1，确认号为ACK+1，选择初始序号seq=y。服务器端进入SYN-RECEIVED状态。4. 最后确认：   - 客户端收到确认报文后，向服务器端给出确认，ACK置为1，确认号为y+1，自身序号为x+1。TCP连接成功建立，客户端进入ESTABLISHED状态。补充说明：- TCP连接采用三次握手的主要目的是防止已失效的连接请求报文段误导服务器，导致资源浪费。- 四次挥手过程中，服务器端和客户端分别发起连接释放请求，最终确认释放连接。- TCP连接释放的过程相对复杂，保障网络和系统资源的有效利用。
说说TCP/IP 五层模型,五层协议体系结构结合了OSI模型和TCP/IP模型的优点，既简洁又能将每一层描述清楚。在计算机网络中要做到正确的数据交换，就必须提前约定好相应的规则。它是一个协议栈，就是为了统一计算机网络标准，方便数据的交换。1. 应用层：   - 应用层是体系结构中的最高层，定义了应用进程间通信和交互的规则。本层任务就是通过应用进程间的信息数据流通完成特定的网络应用（软件、Web应用等）。因为不同的应用程序都需要不同的应用层协议，所以应用层协议较多，如万维网应用的HTTP协议、电子邮件的SMTP协议、文件传送的DTP协议等。请将应用层交互的数据称为报文，以免产生概念的混淆。    - 协议： HTTP、HTTPS、FTP、TFTP、SMTP等2. 运输层：   - 运输层的任务是负责向两个计算机中进程之间的通信提供一种通用的数据传输服务，应用层通过运输层可以传输报文。通用是指不会针对特定的应用层协议进行详细的划分，多种应用层协议公用同一个运输层服务，所以运输层有复用的功能。当然也有分发的功能，指将接受到的信息分别交付到应用层不同的进程中。    - 协议： UDP、TCP3. 网络层：   - 网络层的任务是负责为网络上不同的主机提供通信服务。在发送数据时，网络层将运输层产生的报文段或者用户数据报封装成分组或者包（packet）进行传送。由于网络层使用IP协议，所以分组或包（packet）也叫IP数据报，简称数据报。网络层还需要寻找合适的路由路线，让源主机运输层发送下来的数据报能通过路由器找到目的主机。    - 协议： ICMP、IGMP、IP（IPv4、IPv6）、ARP、RARP4. 数据链路层：   - 数据链路层简称链路层。两个节点传输数据时，链路层将网络层交下来的数据报组装成帧，在链路上传送帧。每一帧都包括数据和控制信息（同步信息、地址信息、差错控制等）。5. 物理层：   - 物理层上数据的单位是Bit比特，数据的传输都是通过0（或1）比特流来实现的，而0（或1）比特流与电压的高低有关。物理层中比特流的传输不再加控制信息，需要注意的是比特流应从首部开始传送。
HTTP 和 HTTPS 的区别,由于HTTP简单快速的特性，当客户端向服务器端请求数据的时候，只需要传送请求方法和路径就可以取到结果，基于TCP，默认端口号为80，耗时可以简略计算为1RTT，传递的数据全部是明文传输，几乎没有安全性。HTTPS是基于TLS的，而TLS又基于TCP，当客户端向服务器端请求数据的时候，服务器大概率会将客户端重定向到该服务器的443端口，进行新的TCP连接，此时服务器会返回一个证书文件，而不是响应报文体。此时客户端验证证书文件紧接创建对称密钥，之后重新和服务器建立TLS连接，当服务器返回ACK确认之后，连接正式建立，此时上方整个过程耗时为3RTT，并且之后和服务器的通信数据都是通过对称密钥加密过的，几乎无法破解。HTTP和HTTPS的不同点总结如下：- HTTP是基于TCP的，而HTTPS是基于TLS的- HTTP的往返时间为1RTT，而HTTPS的往返时间为3RTT- HTTP只需要创建一次TCP连接，而HTTPS需要创建两次TCP连接- HTTP的默认端口号为80，而HTTPS的默认端口号为443- HTTP的安全性很差，而HTTPS的安全性很强HTTPS虽然在安全方面有很大的优势，但是缺点也很明显，如下：- HTTPS握手阶段耗费时间，几乎是HTTP的数倍，会延长页面的首次绘制时间和增加耗电- HTTPS的效率没有HTTP高，如果部分数据内容实际上并不需要加密，会平白浪费计算机资源- HTTPS的证书需要购买，功能越强大的证书价格更高- HTTPS的加密并不能阻止某些网络攻击，如黑客攻击、拒绝服务攻击等
GET 和 POST 的区别,"- get主要用来获取数据，post主要用来提交数据。- get的参数有长度限制，最长2048字节，而post没有限制。- get的参数会附加在url之 ，以 "" ？ ""分割url和传输数据，多个参数用 ""&""连接，而post会把参数放在http请求体中。- get是明文传输，可以直接通过url看到参数信息，post是放在请求体中，除非用工具才能看到。- get请求会保存在浏览器历史记录中，也可以保存在web服务器日志中。- get在浏览器回退时是无害的，而post会再次提交请求。- get请求会被浏览器主动缓存，而post不会，除非手动设置。- get请求只能进行url编码，而post支持多种编码方式。- get请求的参数数据类型只接受ASCII字符，而post没有限制。"
说说拥塞控制机制,拥塞控制就是防止太多的数据进入到网络中，这样可以使网络中的路由器或者链路不会过载，首先要求当前的网络可以承受住现有的网络负荷，它是一个全局性的过程，拥塞控制的算法有以下四种：- 慢启动（slow-start）：当客户端发送数据的时候，如果一次性把大量的数据字节发送到网络中，就有可能引起网络拥塞，因为并不清楚网络的负荷状态。所以较好的方法是先探测一下，由小到大逐渐增大发送窗口，也就是慢慢地增大窗口数值。通常刚开始发送报文段时先把拥塞窗口cwnd设置为一个最大报文段MSS的值，每收到一对新的报文段确认后，把拥塞窗口的数值再加一个MSS。- 拥塞避免（congestion avoidance）：让拥塞窗口cwnd缓缓地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍，让拥塞窗口按照线性规律慢慢增长，比慢开始算法的拥塞窗口增长速率慢很多。- 快重传（fast retransmit）：要求接收方每收到一个失序的报文段之后就立即发出重复确认而不是等待自己发送数据时捎带确认，为的就是让发送方能尽早地知道有报文段没有到达接收方。- 快恢复（fast recovery）：两个要点，一是当发送方连续收到三个重复确认时，就执行”乘法减小“算法，把慢开始门限ssthresh减半，这是为了预防网络发生拥塞。二是发送方认为网络很可能没有发生阻塞，因此不会执行慢开始算法，而是把cwnd值设置成慢开始门限ssthresh减半之后的数值，然后执行拥塞避免算法，使拥塞窗口呈线性增长。
说说 HTTPS 加解密的过程是怎么样的,HTTPS数据加解密过程中数据进行对称加密，对称加密所使用的密钥通过非对称加密传输。HTTPS协议的加密过程可以分为两个阶段：- 证书的认证阶段： 在此阶段，使用非对称加解密算法对数据传送阶段的对称加解密密钥进行加密和解密。客户端通过验证服务器的数字证书，获取服务器的公钥，并使用该公钥对对称加密密钥进行加密，以确保安全地传输密钥到服务器端。- 数据传送阶段： 在此阶段，客户端通过证书认证阶段获取到了目标服务器的对称加解密密钥。数据在传输过程中，使用该密钥进行对称加密，并传输给服务器，确保数据的安全性。在整个HTTPS数据传输的过程中涉及到四个密钥：1. CA机构的公钥，用于验证数字证书的可信任性。2. 服务器端的公钥，用于在证书认证阶段进行非对称加密。3. 服务器端的私钥，用于在证书认证阶段进行非对称解密。4. 客户端生成的随机密钥，用于在数据传送阶段进行对称加解密。一个HTTPS请求可以分为两个阶段，证书认证阶段和数据传送阶段，具体细分为六个步骤：1. 客户端向服务器发起HTTPS请求，连接到服务器的443（默认）端口。2. 服务器端使用密钥对，发送数字证书给客户端，其中包含公钥。3. 客户端验证服务器的数字证书合法性，并生成一个随机值作为数据传送阶段的对称加密密钥，并使用服务器的公钥对其进行加密，生成密文。4. 客户端再次向服务器发起HTTP请求，将对称加密密钥的密文发送给服务器。5. 服务器使用私钥解密客户端发送的密文，获取对称加密密钥，并使用该密钥对需要返回给客户端的数据进行加密，生成密文，然后发送给客户端。6. 客户端接收到服务器发送的密文，使用本地的密钥对其进行解密，得到数据明文，完成整个HTTPS传输过程。
UDP 怎么样可以实现可靠的传输,UDP不是面向连接的协议，因此资源消耗小、处理速度快的优点使其在音频、视频和普通数据传输中得到广泛应用。即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。如果想要使用UDP实现数据的可靠传输，就需要通过应用层来实现。在应用层实现UDP的可靠传输关键点主要有两个：1. 提供超时重传机制： 这可以避免数据报丢失的问题。具体实现时，可以在UDP数据报的首部定义确认序列号和时间戳。时间戳用来计算数据报传输的往返时间（RTT），从而得到合适的重传超时时间（RTO）。然后按照等-停的方式发送数据报，即收到对端的确认之后才发送下一个数据报。当超过重传超时时间时，本端会重传数据报，并将RTO扩大为原来的两倍，重新开始计时。2. 提供确认序列号： 这可以保证数据在传输过程中的正确排序。在请求端，接收到一个数据报后，会取出该数据报首部的时间戳和确认序列号，并在本端添加确认数据报首部后发送给对端。同时，根据确认序列号对已接收的数据报进行排序，并丢弃重复的数据报。
缓存穿透、击穿、雪崩的区别,缓存穿透是指客户端查询了根本不存在的数据，使得这个请求直达存储层，导致其负载过大甚至造成宕机。这种情况可能是由于业务层误将缓存和库中的数据删除造成的，当然也不排除有人恶意攻击，专门访问库中不存在的数据导致缓存穿透。我们可以通过缓存空对象的方式和布隆过滤器两种方式来解决这一问题。缓存空对象是指当存储层未命中后，仍然将空值存入缓存层 ，当客户端再次访问数据时，缓存层直接返回空值。还可以将数据存入布隆过滤器，访问缓存之前以过滤器拦截，若请求的数据不存在则直接返回空值。  缓存击穿：当一份访问量非常大的热点数据缓存失效的瞬间，大量的请求直达存储层，导致服务崩溃。缓存击穿可以通过热点数据不设置过期时间来解决，这样就不会出现上述的问题，这是“物理”上的永不过期。或者为每个数据设置逻辑过期时间，当发现该数据逻辑过期时，使用单独的线程重建缓存。除了永不过期的方式，我们也可以通过加互斥锁的方式来解决缓存击穿，即对数据的访问加互斥锁，当一个线程访问该数据时，其他线程只能等待。这个线程访问过后，缓存中的数据将被重建，届时其他线程就可以直接从缓存中取值。  缓存雪崩：是指当某一时刻缓存层无法继续提供服务，导致所有的请求直达存储层，造成数据库宕机。可能是缓存中有大量数据同时过期，也可能是Redis节点发生故障，导致大量请求无法得到处理。缓存雪崩的解决方式有三种；第一种是在设置过期时间时，附加一个随机数，避免大量的key同时过期。第二种是启用降级和熔断措施，即发生雪崩时，若应用访问的不是核心数据，则直接返回预定义信息/空值/错误信息。或者在发生雪崩时，对于访问缓存接口的请求，客户端并不会把请求发给Redis，而是直接返回。第三种是构建高可用的Redis服务，也就是采用哨兵或集群模式，部署多个Redis实例，这样即使个别节点宕机，依然可以保持服务的整体可用。
Redis 如何与数据库保持双写一致性,保证缓存和数据库的双写一致性，共有四种同步策略，即先更新缓存再更新数据库、先更新数据库再更新缓存、先删除缓存再更新数据库、先更新数据库再删除缓存。先更新缓存的优点是每次数据变化时都能及时地更新缓存，这样不容易出现查询未命中的情况，但这种操作的消耗很大，如果数据需要经过复杂的计算再写入缓存的话，频繁的更新缓存会影响到服务器的性能。如果是写入数据比较频繁的场景，可能会导致频繁的更新缓存却没有业务来读取该数据。 删除缓存的优点是操作简单，无论更新的操作复杂与否，都是直接删除缓存中的数据。这种做法的缺点则是，当删除了缓存之后，下一次查询容易出现未命中的情况，那么这时就需要再次读取数据库。 那么对比而言，删除缓存无疑是更好的选择。那么我们再来看一下先操作数据库和后操作数据库的区别；先删除缓存再操作数据库的话，如果第二步骤失败可能导致缓存和数据库得到相同的旧数据。先操作数据库但删除缓存失败的话则会导致缓存和数据库得到的结果不一致。出现上述问题的时候，我们一般采用重试机制解决，而为了避免重试机制影响主要业务的执行，一般建议重试机制采用异步的方式执行。当我们采用重试机制之后由于存在并发，先删除缓存依然可能存在缓存中存储了旧的数据，而数据库中存储了新的数据，二者数据不一致的情况。 所以我们得到结论：先更新数据库、再删除缓存是影响更小的方案。如果第二步出现失败的情况，则可以采用重试机制解决问题。
数据库引擎有哪些，各自有什么区别,InnoDB 引擎是 MySQL 的事务安全（ACID 兼容）存储引擎，具有提交、回滚和崩溃恢复功能来保护用户数据；行级锁定读取增加了多用户并发性和性能；将用户数据存储在聚集索引中，以减少基于主键的常见查询的 I/O；还支持 FOREIGN KEY 维护数据完整性。MyISAM引擎的表占用空间较小，表级锁定限制了读/写工作负载的性能，因此它通常用于只读或以读取为主的场景。 Memory引擎是将所有数据存储在 RAM 中，以便在需要快速查找非关键数据的环境中进行快速访问，以前被称为 HEAP 引擎。 Archive引擎非常适合存储大量的独立的，作为历史记录的数据，因为它们不经常被读取。它 拥有高效的插入速度，但其对查询的支持相对较差。 Cluster/NDB是高冗余的存储引擎，用多台数据机器联合提供服务以提高整体性能和安全性。适合数据量大，安全和性能要求高的应用。 Federated引擎提供连接单独的 MySQL 服务器，从多个物理服务器创建一个逻辑数据库的能力，非常适合分布式或数据集市环境。
说说内联函数和函数的区别，内联函数的作用,内联函数和函数的区别： - 内联函数比普通函数多了关键字 inline； - 内联函数避免了函数调用的开销；普通函数有调用的开销； - 普通函数在被调用的时候，需要寻址（函数入口地址）；内联函数不需要寻址； - 内联函数有一定的限制，内联函数体要求代码简单，不能包含复杂的结构控制语句，如果内联函数函数体过于复杂，编译器将自动把内联函数当成普通函数来执行；普通函数没有这个要求。 内联函数的作用： 因为函数调用时候需要创建时间、参数传入传递等操作，造成了时间和空间的额外开销。通过编译器预处理，在调用内联函数的地方将内联函数内的语句复制到调用函数的地方，也就是直接展开代码执行，从而提高了效率，减少了一些不必要的开销。同时内联函数还能解决宏定义的问题。
简述一下堆和栈的区别,堆和栈主要有如下几点区别：管理方式、空间大小、是否产生内存碎片、生长方向、分配方式、分配效率。 管理方式 对于栈来讲，是由编译器自动管理，无需手动控制；对于堆来说，分配和释放都是由程序员控制的。 空间大小 总体来说，栈的空间是要小于堆的。堆内存几乎是没有什么限制的；但是对于栈来讲，一般是有一定的空间大小的。 碎片问题 对于堆来讲，由于分配和释放是由程序员控制的（利用new/delete 或 malloc/free），频繁的操作势必会造成内存空间的不连续，从而造成大量的内存碎片，使程序效率降低。对于栈来讲，则不会存在这个问题，因为栈是先进后出的数据结构，在某一数据弹出之前，它之前的所有数据都已经弹出。 生长方向 对于堆来讲，生长方向是向上的，也就是沿着内存地址增加的方向，对于栈来讲，它的生长方式是向下的，也就是沿着内存地址减小的方向增长。 分配方式 堆都是动态分配的，没有静态分配的堆。栈有两种分配方式：静态分配和动态分配，静态分配是编译器完成的，比如局部变量的分配；动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，它的动态分配是由编译器实现的，无需我们手工实现。 分配效率 栈是机器系统提供的数据结构，计算机会在底层对栈提供支持，分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率很高。堆则是 C/C++ 函数提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率要比栈底的多。
说一说什么是内存泄露，如何检测,内存泄漏（Memory Leak）是指程序中已动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。 避免内存泄露的方法主要就是要有良好的编码习惯，动态开辟内存空间，及时释放内存。也可以采用智能指针来避免内存泄露。 可以采用静态分析技术、源代码插装技术等进行检测。常见的一些检测工作有：LCLink、ccmalloc、Dmalloc、Electric Fence、Leaky、LeakTracer、MEMWATCH、Valgrind、KCachegrind等等。说说 malloc 的实现原理malloc() 的整体思想是先向操作系统申请一块大小适当的内存，然后自己管理，即内存池。 malloc() 分配空间有一个数据结构，允许它来区分边界，区分已分配和空闲的空间，数据结构中包含一个头部信息和有效载荷，有效载荷的首地址就是 malloc() 返回的地址，可能在尾部还有填充，为了保持内存对齐。头部相当于该数据结构的元数据，其中包含了块大小和是否是空闲空间的信息，这样可以根据头地址和块大小的地址推出下一个内存块的地址，这就是隐式链表。 malloc() 基本的实现原理就是维护一个内存空闲链表，当申请内存空间时，搜索内存空闲链表，找到适配的空闲内存空间，然后将空间分割成两个内存块，一个变成分配块，一个变成新的空闲块。如果没有搜索到，那么就会调用 sbrk() 推进 brk 指针来申请内存空间。搜索空闲块最常见的算法有：首次适配，下一次适配，最佳适配。 - 首次适配：第一次找到足够大的内存块就分配，这种方法会产生很多的内存碎片。 - 下一次适配：也就是说等第二次找到足够大的内存块就分配，这样会产生比较少的内存碎片。 - 最佳适配：对堆进行彻底的搜索，从头开始遍历所有块，使用数据区大小大于 size 且差值最小的块作为此次分配的块。 在释放内存块后，如果不进行合并，那么相邻的空闲内存块还是相当于两个内存块，会形成一种假碎片。所以当释放内存后，需要将两个相邻的内存块进行合并。 还有一种实现方式则是采用显示空闲链表，这个是真正的链表形式。在之前的有效载荷中加入了前驱和后驱的指针，也可以称为双向链表。维护空闲链表的的方式第一种是用后进先出（LIFO），将新释放的块放置在链表的开始处。另一种方法是按照地址的顺序来维护。
说说 new 的实现原理，new 和 malloc 的区别,new 的实现原理： 如果是简单类型，则直接调用 operator new()，在 operator new() 函数中会调用 malloc() 函数，如果调用 malloc() 失败会调用 _callnewh()，如果 _callnewh() 返回 0 则抛出 bac_alloc 异常，返回非零则继续分配内存。 如果是复杂类型，先调用 operator new()函数，然后在分配的内存上调用构造函数。 new 和 malloc 的区别 - new 是操作符，而 malloc 是函数； - 使用 new 操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算，而 malloc 则需要显式地指出所需内存的尺寸； - new 分配失败的时候会直接抛出异常，malloc 分配失败会返回 NULL； - 对于非简单类型，new 在分配内存后，会调用构造函数，而 malloc 不会； - new 分配成功后会返回对应类型的指针，而 malloc 分配成功后会返回 void * 类型； - malloc 可以分配任意字节，new 只能分配实例所占内存的整数倍数大小； - new 可以被重载，而 malloc 不能被重载； - new 操作符从自由存储区上分配内存空间，而 malloc 从堆上动态分配内存； - 使用 malloc 分配的内存后，如果在使用过程中发现内存不足，可以使用 realloc 函数进行内存重新分配实现内存的扩充，new 没有这样直观的配套设施来扩充内存。
简述一下 C++ 中的四种类型转换,使用 C 风格的类型转换可以把想要的任何东西转换成我们需要的类型，但是这种类型转换太过松散，对于这种松散的情况，C++ 提供了更严格的类型转换，可以提供更好的控制转换过程，并添加 4 个类型转换运算符，使转换过程更规范：static_cast、dynamic_cast、const_cast、reinterpret_cast。 static_cast 静态转换 用于类层次结构中基类（父类）和派生类（子类）之间指针或引用的转换 - 进行上行转换（把派生类的指针或引用转换成基类表示）是安全的 - 进行下行转换（把基类指针或引用转换成派生类表示）时，由于没有动态类型检查，所以是不安全的 用于基本数据类型之间的转换，如把 int 转换成 char，把 char 转换成 int。这种转换的安全性也要开发人员来保证 dynamic_cast 动态转换 dynamic_cast 主要用于类层次间的上行转换和下行转换 在类层次间进行上行转换时，dynamic_cast 和 static_cast 的效果是一样的 在进行下行转换时，dynamic_cast 具有类型检查的功能，比 static_cast 更安全 const_cast 常量转换 该运算符用来修改类型的const属性 常量指针被转化成非常量指针，并且仍然指向原来的对象 常量引用被转换成非常量引用，并且仍然指向原来的对象 注意:不能直接对非指针和非引用的变量使用 const_cast 操作符 reinterpret_cast 重新解释转换 这是最不安全的一种转换机制，最有可能出问题 主要用于将一种数据类型从一种类型转换为另一种类型，它可以将一个指针转换成一个整数，也可以将一个整数转换成一个指针
说说迭代器失效原因，有哪些情况,STL 中某些容器调用了某些成员方法后会导致迭代器失效。例如 vector 容器，如果调用 reserve() 来增加容器容量，之前创建好的任何迭代器（例如开始迭代器和结束迭代器）都可能会失效，这是因为，为了增加容器的容量，vector 容器的元素可能已经被复制或移到了新的内存地址。 序列式容器迭代器失效 对于序列式容器，例如 vector、deque，由于序列式容器是组合式容器，当当前元素的迭代器被删除后，其后的所有元素的迭代器都会失效，这是因为 vector、deque都是连续存储的一段空间，所以当对其进行 erase 操作时，其后的每一个元素都会向前移一个位置。解决：erase 返回下一个有效的迭代器。 关联式容器迭代器失效 对于关联容器，例如如 map、 set，删除当前的迭代器，仅仅会使当前的迭代器失效，只要在 erase 时，递增当前迭代器即可。这是因为 map 之类的容器，使用了红黑树来实现，插入、删除一个节点不会对其他点造成影响。erase 迭代器只是被删元素的迭代器失效，但是返回值为 void，所以要采用 erase(iter++) 自增方式删除迭代器。
说说 map 实现原理，各操作的时间复杂度是多少,map 实现原理 map 内部实现了一个红黑树（红黑树是非严格平衡的二叉搜索树，而 AV L是严格平衡二叉搜索树），红黑树有自动排序的功能，因此 map 内部所有元素都是有序的，红黑树的每一个节点都代表着 map 的一个元素。因此，对于 map 进行的查找、删除、添加等一系列的操作都相当于是对红黑树进行的操作。map 中的元素是按照二叉树（又名二叉查找树、二叉排序树）存储的，特点就是左子树上所有节点的键值都小于根节点的键值，右子树所有节点的键值都大于根节点的键值，使用中序遍历可将键值按照从小到大遍历出来。 各操作的时间复杂度 插入: O(logN) 查看: O(logN) 删除: O(logN)
说说红黑树的特性，为什么要有红黑树,虽然平衡树解决了二叉查找树退化为近似链表的缺点，能够把查找时间控制在 O(logn)，不过却不是最佳的，因为平衡树要求每个节点的左子树和右子树的高度差至多等于1，这个要求实在是太严了，导致每次进行插入/删除节点的时候，几乎都会破坏平衡树的第二个规则，进而我们都需要通过左旋和右旋来进行调整，使之再次成为一颗符合要求的平衡树。显然，如果在那种插入、删除很频繁的场景中，平衡树需要频繁着进行调整，这会使平衡树的性能大打折扣，为了解决这个问题，于是有了红黑树，红黑树具有如下特点：  1、具有二叉查找树的特点；  2、根节点是黑色的；  3、每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存数据；  4、任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；  5、每个节点，从该节点到达其可达的叶子节点是所有路径，都包含相同数目的黑色节点。 
说说 C++ 中智能指针和指针的区别是什么,智能指针 如果在程序中使用 new 从堆（自由存储区）分配内存，等到不需要时，应使用 delete 将其释放。C++ 引入了智能指针 auto_ptr，以帮助自动完成这个过程。随后的编程体验（尤其是使用STL）表明，需要有更精致的机制。基于程序员的编程体验和 BOOST 库提供的解决方案，C++11 摒弃了 auto_ptr，并新增了三种智能指针：unique_ptr、shared_ptr 和 weak_ptr。所有新增的智能指针都能与 STL 容器和移动语义协同工作。 指针 C 语言规定所有变量在使用前必须先定义，指定其类型，并按此分配内存单元。指针变量不同于整型变量和其他类型的变量，它是专门用来存放地址的，所以必须将它定义为“指针类型”。 3. 智能指针和普通指针的区别 智能指针和普通指针的区别在于智能指针实际上是对普通指针加了一层封装机制，区别是它负责自动释放所指的对象，这样的一层封装机制的目的是为了使得智能指针可以方便的管理一个对象的生命期。指针是一种数据类型，用于保存内存地址，而智能指针是类模板。
说说三种智能指针实现原理和使用场景，以及其线程安全,1. 智能指针实现原理 建立所有权（ownership）概念，对于特定的对象，只能有一个智能指针可拥有它，这样只有拥有对象的智能指针的析构函数会删除该对象。然后，让赋值操作转让所有权。这就是用于 auto_ptr 和 unique_ptr 的策略，但 unique_ptr 的策略更严格，unique_ptr 能够在编译期识别错误。 跟踪引用特定对象的智能指针计数，这称为引用计数（reference counting）。例如，赋值时，计数将加 1，而指针过期时，计数将减 1. 仅当最后一个指针过期时，才调用 delete。这是 shared_ptr 采用的策略。  2. 使用场景 如果程序要使用多个指向同一个对象的指针，应该选择 shared_ptr； 如果程序不需要多个指向同一个对象的指针，则可以使用 unique_ptr; 如果使用 new [] 分配内存，应该选择 unique_ptr; 如果函数使用 new 分配内存，并返回指向该内存的指针，将其返回类型声明为 unique_ptr 是不错的选择。  3. 线程安全 shared_ptr 智能指针的引用计数在手段上使用了 atomic 原子操作，只要 shared_ptr 在拷贝或赋值时增加引用，析构时减少引用就可以了。首先原子是线程安全的，所有 shared_ptr 智能指针在多线程下引用计数也是安全的，也就是说 shared_ptr 智能指针在多线程下传递使用时引用计数是不会有线程安全问题的。 但是指向对象的指针不是线程安全的，使用 shared_ptr 智能指针访问资源不是线程安全的，需要手动加锁解锁。智能指针的拷贝也不是线程安全的。
说说左值、右值、左值引用、右值引用、右值引用的使用场景,左值 在 C++ 中可以取地址的、有名字的就是左值 int a = 10; // 其中 a 就是左值 右值 不能取地址的、没有名字的就是右值 int a = 10; // 其中 10 就是右值右值 左值引用 左值引用就是对一个左值进行引用。传统的 C++ 引用（现在称为左值引用）使得标识符关联到左值。左值是一个表示数据的表达式（如变量名或解除引用的指针），程序可获取其地址。最初，左值可出现在赋值语句的左边，但修饰符 const 的出现使得可以声明这样的标识符，即不能给它赋值，但可获取其地址： int n; int * pt = new int; const int b = 101; int & rn = n; int & rt = *pt; const int & rb = b; const int & rb = 10; 右值引用 右值引用就是对一个右值进行引用。C++ 11 新增了右值引用（rvalue reference），这种引用可指向右值（即可出现在赋值表达式右边的值），但不能对其应用地址运算符。右值包括字面常量（C-风格字符串除外，它表示地址）、诸如 x + y 等表达式以及返回值的函数（条件是该函数返回的不是引用），右值引用使用 && 声明： int x = 10; int y = 23; int && r1 = 13; int && r2 = x + y; double && r3 = std::sqrt(2.0); 右值引用的使用场景 右值引用可以实现移动语义、完美转发。
说说 C++ Lambda 表达式用法及实现原理,Lambda 表达式语法：[外部变量访问方式说明符] (参数) mutable noexcept/throw() -> 返回值类型 {    函数体;};其中各部分的含义分别为：1. [外部变量方位方式说明符] [ ] 方括号用于向编译器表明当前是一个Lambda 表达式，其不能被省略。在方括号内部，可以注明当前 Lambda 函数的函数体中可以使用哪些“外部变量”。所谓外部变量，指的是和当前 lambda 表达式位于同一作用域内的所有局部变量。[外部变量]的定义方式：  - 外部变量格式：功能    - [] ：空方括号表示当前 lambda 匿名函数中不导入任何外部变量。           - [=]：只有一个 = 等号，表示以值传递的方式导入所有外部变量；            - [&]：只有一个 & 符号，表示以引用传递的方式导入所有外部变量；          - [val1，val2，...] ：表示以值传递的方式导入 val1、val2 等指定的外部变量，同时多个变量之间没有先后次序；     - [&val1，&val2，...]：表示以引用传递的方式导入 val1、val2等指定的外部变量，多个变量之间没有前后次序；     - [val，&val2，...] ：以上 2 种方式还可以混合使用，变量之间没有前后次序。              - [=，&val1，...]：表示除 val1 以引用传递的方式导入外，其它外部变量都以值传递的方式导入。     - [this] ： 表示以值传递的方式导入当前的 this 指针。 2. (参数) 和普通函数的定义一样，Lambda 匿名函数也可以接收外部传递的多个参数。和普通函数不同的是，如果不需要传递参数，可以连同 () 小括号一起省略；  3. mutable 此关键字可以省略，如果使用则之前的 () 小括号将不能省略（参数个数可以为 0）。默认情况下，对于以值传递方式引入的外部变量，不允许在 Lambda 表达式内部修改它们的值（可以理解为这部分变量都是 const 常量）。而如果想修改它们，就必须使用 mutable 关键字。对于以值传递方式引入的外部变量，Lambda  表达式修改的是拷贝的那一份，并不会修改真正的外部变量。  4. noexcept/throw() 可以省略，如果使用，在之前的 () 小括号将不能省略（参数个数可以为 0）。默认情况下，Lambda  函数的函数体中可以抛出任何类型的异常。而标注 noexcept 关键字，则表示函数体内不会抛出任何异常；使用 throw() 可以指定 Lambda  函数内部可以抛出的异常类型。  5. -> 返回值类型 指明 Lambda  匿名函数的返回值类型。如果 Lambda  函数体内只有一个 return 语句，或者该函数返回 void，则编译器可以自行推断出返回值类型，此情况下可以直接省略 -> 返回值类型。  6. 函数体 和普通函数一样，Lambda  匿名函数包含的内部代码都放置在函数体中。该函数体内除了可以使用指定传递进来的参数之外，还可以使用指定的外部变量以及全局范围内的所有全局变量。 编译器实现 Lambda 表达式大致分为一下几个步骤：1. 创建一个未命名的类，实现构造函数，使用 Lambda 表达式的函数体重载 operator()（所以 Lambda 表达式 也叫匿名函数对象） 2. 创建未命名的类的对象 3. 通过对象调用 operator()
说说单例设计模式,概念 单例设计模式（Singleton Pattern）是一种比较简单的设计模式。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。注意： - 单例类只能有一个实例。 - 单例类必须自己创建自己的唯一实例。 - 单例类必须给所有其他对象提供这一实例。 单例设计模式的优缺点 优点： - 单例模式可以保证内存里只有一个实例，减少了内存的开销。 - 可以避免对资源的多重占用。 - 单例模式设置全局访问点，可以优化和共享资源的访问。 缺点： - 单例模式一般没有接口，扩展困难。如果要扩展，则除了修改原来的代码，没有第二种途径，违背开闭原则。 - 在并发测试中，单例模式不利于代码调试。在调试过程中，如果单例中的代码没有执行完，也不能模拟生成一个新的对象。 - 单例模式的功能代码通常写在一个类中，如果功能设计不合理，则很容易违背单一职责原则。  C++ 单例设计模式的实现 - 私有化构造函数、拷贝构造函数、赋值函数 - 定义一个私有的本类的静态对象成员 - 定义一个公共的访问该示例静态成员方法，返回该静态对象成员 单例设计模式的种类 - 懒汉式：获取该类的对象时才创建该类的实例 - 饿汉式：获取该类的对象之前已经创建好该类的实例 
讲讲 B 树和 B+ 树,它们都是平衡多路查找树，是在二叉查找树基础上的改进数据结构。在二叉查找树上查找一个数据时，最坏情况的查找次数为树的深度，当数据量很大时，查询次数可能还是很大，造成大量的磁盘IO，从而影响查询效率； 	为了减少磁盘IO的次数，必须降低树的深度，因此在二叉查找树基础上将树改成了多叉加上一些限制条件，就形成了B树； 	B+树是B树的变种，区别主要是：对于k阶的B树，每个中间节点只存k-1个值k个指针，而B+树存k个值和k个指针；B树中所有节点中值的总集是全部关键字集合，而B+树中所有叶子节点值的总集就是全部关键字集合；B+树为所有叶子节点增加了链接，从而实现了快速的范围查找。
